<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📖&lt;/text&gt;&lt;/svg&gt;">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>A Survey on Multimodal Large Language Models&nbsp;|&nbsp;Paper Reading</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="A Survey on Multimodal Large Language Models">
  
    <meta name="description" content="formulate MLLMs and delineate its related concepts; discussed key techniques like M-IT, M-ICT, M-CoT, LAVR.">
    <meta property="og:description" content="formulate MLLMs and delineate its related concepts; discussed key techniques like M-IT, M-ICT, M-CoT, LAVR.">
  
  
    <meta property="og:image" content="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📝&lt;/text&gt;&lt;/svg&gt;">
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📖&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;🏖️&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>About</span>
        </div>
      </a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
      <div class="Header__Icon">
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📝&lt;/text&gt;&lt;/svg&gt;"></span>
      </div>
    
    <h1 class="Header__Title">A Survey on Multimodal Large Language Models</h1>
    
      <div class="DateTagBar">
        
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--yellow">
            <a href="tag/survey.html">survey</a>
          </span>
        
      </div>
    
  </header>
  <article id="https://www.notion.so/559f1d36f0c94fa9b500ab004c9a0540" class="PageRoot"><h1 id="https://www.notion.so/e980e072cc1948cfa3c422803face660" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/e980e072cc1948cfa3c422803face660"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Introducing MLLMs</span></span></h1><ul class="BulletedListWrapper"><li id="https://www.notion.so/8d3e53cdba20416292451516474d2ed4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">a MLLM refers to LLM-based model with the ability to receive and reason with multimodal information.</span></span></li></ul><h1 id="https://www.notion.so/b4a76827a4984aae9b17267888df41e0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/b4a76827a4984aae9b17267888df41e0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1. transform LLMs into multimodal chatbots or task solvers through M-IT </span></span></h1><ul class="BulletedListWrapper"><li id="https://www.notion.so/e76f53ec8f7643529cfa7cbb1af75588" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">instruction tuning: finetuning pre-trained LLMs on a collection of instruction-response datasets.</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/5b2bfd119ec44af2a0bf41424246f635" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">able to generalize to unseen tasks by following new instructions, thus boosting zero-shot performance</span></span></li></ul></li></ul><h2 id="https://www.notion.so/f56d74dfe89349b29eec7ce5ac4952a7" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/f56d74dfe89349b29eec7ce5ac4952a7"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1.1 adaptation to multimodality</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/81ef97ec783545cb9a6a484ece15f040" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">in order to extend instruction tuning to multimodality, the corresponding adaptations are necessary for both data and model architecture.</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/9ad323c4112149b595db699a569770c4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">reformat existing benchmark datasets into a instruction-response style</span></span></li></ul><div id="https://www.notion.so/b24b10d6d33c4a41900e12d3a8fbc0e9" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2f766b29-2ea4-4bd3-b5a4-e00aa9e137a5%2Ff81f0bf0-bb6c-4b98-bb97-e9046d085360%2FUntitled.png?width=624&amp;table=block&amp;id=b24b10d6-d33c-4a41-900e-12d3a8fbc0e9"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2f766b29-2ea4-4bd3-b5a4-e00aa9e137a5%2Ff81f0bf0-bb6c-4b98-bb97-e9046d085360%2FUntitled.png?width=624&amp;table=block&amp;id=b24b10d6-d33c-4a41-900e-12d3a8fbc0e9" style="width:624px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/1ef6b1b461d04052af4a3c22095bdc37" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">instruction template is flexible and subject to manual designs</span></span></li></ul><div id="https://www.notion.so/62b393f3928d4c589ad0472c8ffe7a1c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h2 id="https://www.notion.so/d304c24fef3f42acba06272a9afa6c76" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/d304c24fef3f42acba06272a9afa6c76"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1.2 Data preparation</span></span></h2></li></ul><h3 id="https://www.notion.so/2bb782600ff9468491c308cb48239fd0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2bb782600ff9468491c308cb48239fd0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">benchmark adaptation</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/4a0e22d12aee4aa0a1ed11d0c83b09e6" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">hand-craft a pool of candidate instructions and sample one of them during training.</span></span></li><li id="https://www.notion.so/e4ac1f7f040b4917bafae3bc246871fe" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">manually design several seed instructions and use them to prompt GPT to generate more</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/80b63030ac7a4bb8805822d869b1de88" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">instructBLIP inherently prefer short response because it inserts explicitly short and briefly into instruction templates.</span></span></li><li id="https://www.notion.so/1b16e65618db4b838d3ca3b4862ae950" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">prompt GPT with original ones to rephrase </span></span></li></ul><h3 id="https://www.notion.so/c248890e9aa24f57b0333db9be9fc706" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/c248890e9aa24f57b0333db9be9fc706"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">self-instruction for multiple rounds of conversations</span></span></h3><div id="https://www.notion.so/b5bbd0e47eff4d9882629187765bcc55" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">some instruction-following samples are hand-crafted as seed examples, after which ChatGPT/GPT-4 is prompted to generate more instruction samples with the seed samples as guidance.</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/82b6d4008ef9466eab30de6b03fd979f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">LLaVA-Instruct-150k</span></span></li></ul></li></ul><h3 id="https://www.notion.so/afbc3a2ec625422f9a71585eea6e5363" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/afbc3a2ec625422f9a71585eea6e5363"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Hybrid composition</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/6ca615dc70b941dd8d1a8be84fa9d860" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">MultiInstruct probes different strategies for training</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/5825267241b145bc9da899a7afc16d7f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">mixed instruction tuning (combine both types of data and randomly shuffle)</span></span></li><li id="https://www.notion.so/bbcb8729ac104d44aaeb7e9c3aa9377a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">sequential instruction tuning (text data followed by multimodal data)</span></span></li><li id="https://www.notion.so/b134c58061604d519db9209215cf55c8" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">and Adapter-based sequential instruction tuning</span></span></li></ul><h2 id="https://www.notion.so/545fb4960b1b46fcab20e3273c617c5d" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/545fb4960b1b46fcab20e3273c617c5d"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1.3 modality bridging</span></span></h2><h3 id="https://www.notion.so/7e86648be218453ba3ae9e6fa1bbb2f6" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/7e86648be218453ba3ae9e6fa1bbb2f6"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">learnable interface </span></span></h3><div id="https://www.notion.so/f6f9e00df54c451786f77abbacbc1b29" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">challenge is how to efficiently translate visual content into text that LLM can understand.</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/10c1f6ff34d24f458872e9ccf783298e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">query-based approach: leverage learnable query tokens to extract information</span></span></li><li id="https://www.notion.so/4d67504769d544e2b9685ba854c7e302" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">projection-based method: add a linear embedding layer</span></span></li><li id="https://www.notion.so/67804939495847a9870390c4ad61d824" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">PEFT method: LLaMA-Adapter</span></span></li></ul><div id="https://www.notion.so/a10d302646a74decabb80c667ec9a941" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/4b7d624679134d9c9601db97846494c2" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/4b7d624679134d9c9601db97846494c2"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">expert model such as captioning model as an expert</span></span></h3><div id="https://www.notion.so/306e408c43bb49a4b05a997ea3547006" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">convert multimodal data into languages</span></span></p></div><div id="https://www.notion.so/612e752063f24451b5c46db824bec63b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">may not as flexible as adopting a learnable interface</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/f84ce373eadc4dd782330a5822be19ab" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">VideoChat-Text</span></span></li></ul><h2 id="https://www.notion.so/892043e5244342419a8ea96344820c0e" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/892043e5244342419a8ea96344820c0e"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1.4 Evaluation</span></span></h2></li><li id="https://www.notion.so/c4fea87a4c47412f84bf2bee82d2420f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">closed-set</span></span></li><li id="https://www.notion.so/de68a098fb604e3c8db6e03ec23c3097" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">open-set</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/891cdc417e1c41729323681e826a76a5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">manual scoring</span></span></li><li id="https://www.notion.so/8640bc8c484e41ea97ab4c0328fadfb1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">GPT-scoring</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/07655ab4192d4ee486543213163d5eaa" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">GPT-4 can only generate responses based on image-related text content, without accessing the image</span></span></li></ul></li><li id="https://www.notion.so/2f36aaa929dc41f5a8044fb78657b8d3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">sensitivity to assess the robustness to varied instructions → MultiInstruct</span></span></li><li id="https://www.notion.so/04c4520f642a432998c66fd91786e9db" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">object hallucination → POPE</span></span></li><li id="https://www.notion.so/92a849198ea34f19bdd7cfab2fccb9c6" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">safety issues to evaluate robustness to adversarial attacks →On evaluating adversarial robustness</span></span></li></ul></li></ul><div id="https://www.notion.so/9b62196dbfdf4dc59b8f7b8af4874381" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p><div class="Text__Children"><div id="https://www.notion.so/9cff501996494b1f9c705bb3990e06b5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></div></div><h1 id="https://www.notion.so/aa50e2a3c75c44d2ac34eae930a8cf83" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/aa50e2a3c75c44d2ac34eae930a8cf83"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">2 M-ICT</span></span></h1><ul class="BulletedListWrapper"><li id="https://www.notion.so/c3d33aa008b44d5980e5d8acfdbb0a2e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">few-shot; learn from analogy; closely related to instruction-tuning</span></span></li><li id="https://www.notion.so/4e65b0569ac145ccbb46f4a82b68cf74" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">has 2 good traits:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/370a9c0b133049f88461695bcf94e9e6" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">learn from a few examples along with an optional instruction and extrapolate to new questions, thereby solving complex and unseen tasks in a few-shot manner</span></span></li><li id="https://www.notion.so/ac624bc8afdd422ca42457670007c413" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">implemented in a</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"> training-free</strong></span><span class="SemanticString"> manner and thus can be flexibly </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">integrated into different frameworks at inference stage</strong></span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/690dd0d76acd482b8b8b2fa83da76902" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Commented">adding a demonstration set </span></span></span></li></ul></li></ul><div id="https://www.notion.so/502b7b4004884bc7af1ab27bd2d03e18" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2f766b29-2ea4-4bd3-b5a4-e00aa9e137a5%2F24274215-4d73-4600-beef-d8a32156c6aa%2FUntitled.png?width=542&amp;table=block&amp;id=502b7b40-0488-4bc7-af1a-b27bd2d03e18"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2f766b29-2ea4-4bd3-b5a4-e00aa9e137a5%2F24274215-4d73-4600-beef-d8a32156c6aa%2FUntitled.png?width=542&amp;table=block&amp;id=502b7b40-0488-4bc7-af1a-b27bd2d03e18" style="width:542px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div></li><li id="https://www.notion.so/71a5f8d2a4d0438995128a7e21705ac5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">M-ICT is used in 2 scenarios:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/25fbb6179c1443bebfd2afa92e886acf" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">solving various visual reasoning tasks</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/d521d9946cea4e319efdbec751054b11" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">task recognition</span></span></li><li id="https://www.notion.so/e02d0ac6416847368c34bab28b87b597" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">task learning</span></span></li></ul></li><li id="https://www.notion.so/e9835a5a4b4a4377a4a69b065e95c0a2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">teaching LLMs to use external tools</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/475b4f002a2b47d5a9432770d453c977" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">text-only, fine-grained tool usage</span></span></li></ul></li></ul><h1 id="https://www.notion.so/ebea463ca42a4b3e8be2829e8e208ee8" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/ebea463ca42a4b3e8be2829e8e208ee8"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3 M-CoT</span></span></h1><h2 id="https://www.notion.so/d2eb47eb6de148dd9b9d981b43c42a9a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/d2eb47eb6de148dd9b9d981b43c42a9a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3.1 modality bridging can be achieved in two ways</span></span></h2></li><li id="https://www.notion.so/a22adaba3f4742a0904e3db1da3aa08e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">feature fusion</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/8b3513460e9d43d38a5d74e33fad6b0d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">learnable mapping procedure to map visual embeddings to word embedding space</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/d1550b14076348848c003a6affd62ce2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">projection layer</span></span></li><li id="https://www.notion.so/d85fa297c5e645deaee2f254a57fc129" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">CoT-PT</span></span></li><li id="https://www.notion.so/d155e5da3cdb4125b34920592a616326" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Multimodal-CoT: fine-tuned on ScienceQA</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/eba703c7e28d47d296eb3e0984f9619d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">generate the rationale (chain of reasoning steps) and the final answer based on the rationale.</span></span></li></ul></li></ul></li></ul></li><li id="https://www.notion.so/f028cf2b13334f9698f2dd8ddd80d363" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">transform visual input into textual description</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/77ccc02aab3a479880571fe97cbff1c4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">captioning model</span></span></li></ul></li></ul><h2 id="https://www.notion.so/187b46fb5ac24a5684a55735eca2af01" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/187b46fb5ac24a5684a55735eca2af01"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3.2 Learning paradigms</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/d20816c4d38c4ba89827fddd6a06527c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">finetuning</span></span></li><li id="https://www.notion.so/4b9ab2262dc2440a87f757d5d3549e8d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">few-shot learning</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/52bf1d0432e442daa704a627ac102231" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">requires hand-crafting some in-context examples</span></span></li></ul></li><li id="https://www.notion.so/1530de87d9214759b5e5b0820189217f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">zero-shot learning</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/b9dda1bf56d248f8984f45bae1a802ba" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">only by prompting ‘’Let’s think frame by frame” or “What happened between these two keyframes”</span></span></li></ul></li></ul><h1 id="https://www.notion.so/e75a03d2f82e4562a066f07e48a0bfbe" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/e75a03d2f82e4562a066f07e48a0bfbe"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">4 LLM-aided Visual Reasoning: LLMs as helpers</span></span></h1><div id="https://www.notion.so/35cd1b95a38245f69ab83ca0c5457475" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">many works manifest several good traits:</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/ee274866f49540f1a18a60c8b3257953" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">strong generalization abilities</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/5dda0b2193e248ddbf164ad479d0b66b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">leveraging rich open-world knowledge from LLMs</span></span></li></ul></li><li id="https://www.notion.so/6cf806160e874bc5ba46d58336fe9166" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">emergent abilities</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/143d468983b2469e9c58ae3cd2ea24ba" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">perform complex tasks</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/c8798c84c60540cb89e3834b33910ce9" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">MM-REACT interpret meaning beneath the surface of an image</span></span></li></ul></li></ul></li><li id="https://www.notion.so/5af38ed8172a4095b25931ecb0aec6ac" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">better interactivity and control</span></span></li></ul><h2 id="https://www.notion.so/d800f8d7c9ee47fca915568f2493fae4" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/d800f8d7c9ee47fca915568f2493fae4"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">4.1 Training Paradigms</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/aa2b1d5d642d4bf88c04626c0f00d4b1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">training-free</span></span></li><li id="https://www.notion.so/98c89693f991436c9302dd0c76b2b2dd" class="BulletedList"><span class="SemanticStringArray"></span></li></ul><div id="https://www.notion.so/7b7bb29d75634c1d845259cc108ac163" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>
  <footer class="Footer">
  <div>&copy; Paper Reading 2023</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>
</body>

</html>