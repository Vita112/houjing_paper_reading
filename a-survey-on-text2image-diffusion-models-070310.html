<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📖&lt;/text&gt;&lt;/svg&gt;">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>A survey on text2image diffusion models&nbsp;|&nbsp;Paper Reading</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="A survey on text2image diffusion models">
  
  
    <meta property="og:image" content="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📝&lt;/text&gt;&lt;/svg&gt;">
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📖&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;🏖️&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>About</span>
        </div>
      </a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
      <div class="Header__Icon">
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📝&lt;/text&gt;&lt;/svg&gt;"></span>
      </div>
    
    <h1 class="Header__Title">A survey on text2image diffusion models</h1>
    
      <div class="DateTagBar">
        
          <span class="DateTagBar__Item DateTagBar__Date">Posted on Fri, Nov 10, 2023</span>
        
        
      </div>
    
  </header>
  <article id="https://www.notion.so/0703105fa5c14ec4a4d63bab82ebf35f" class="PageRoot PageRoot--FullWidth"><h1 id="https://www.notion.so/bda1de430abe44ba9242f43eaffe05c0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/bda1de430abe44ba9242f43eaffe05c0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Takeaway</span></span></h1><div id="https://www.notion.so/a26519fa9d44493d9b97751286c2ea6b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/3a084ac64123490ba1ad5c083a8c39f0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/3a084ac64123490ba1ad5c083a8c39f0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">What I’m thinking</span></span></h1><div id="https://www.notion.so/2774bf546b844be78604e0aaf2f64fe3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/ac2a2bae9dda4cc69254c86663b3149b" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/ac2a2bae9dda4cc69254c86663b3149b"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1. Background &amp;&amp; Research Problems</span></span></h1><h2 id="https://www.notion.so/16a40c019b0542f38b8a3ed25524d87a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/16a40c019b0542f38b8a3ed25524d87a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">1.1 concepts</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/741b76bf9e9a4d74bd196d8e744c19de" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Diffusion Probabilistic Models(DPMs):</strong></span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/a1ab83461ef94c9ab105ca3adbbc44df" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"> </strong></span><span class="SemanticString">emerges in 2015, a family of generated models that are Markov chains trained with variational inference, whose learning goal is to reserve a process of perturbing the data with noise from sample generation.</span></span></li><li id="https://www.notion.so/310a1d0e4df042b8b2e0c9619394241c" class="BulletedList"><span class="SemanticStringArray"></span></li><li id="https://www.notion.so/1e44bca23fbe4f4587d289dde0eeaaf2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">paper :Deep unsupervised learning using nonequilibrium thermodynamics </span></span></li></ul></li><li id="https://www.notion.so/d0ed3c71e47944c18a7f3749e913208e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Denoising Diffusion Probabilistic Model(DDPM): </strong></span></span></li></ul><h1 id="https://www.notion.so/c6e00c7855694392944c93f683cb6649" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/c6e00c7855694392944c93f683cb6649"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">2. Method</span></span></h1><h2 id="https://www.notion.so/4d4cb0f4792f4a628dc84f398afed85a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/4d4cb0f4792f4a628dc84f398afed85a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">omitted.</span></span></h2><div id="https://www.notion.so/74825ffabaf44353bd843229ab1a546a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/995e141a8d1446f7bb1e543c838ede12" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/995e141a8d1446f7bb1e543c838ede12"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3. Multimodal guidance for image synthesis and editing</span></span></h1><ul class="BulletedListWrapper"><li id="https://www.notion.so/e742ca3ee5ce472897ed475913f631e8" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgPink"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">conditional generation, unified discrete token sequence, </strong></mark></span></span></li></ul><div id="https://www.notion.so/3644fa6d6131413ba1d69ffcd9c3f06d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">create realistic images or edit real images by incorporating multimodal guidance as various conditions.</span></span></p></div><div id="https://www.notion.so/aed6fdd3c3554e8c981fe4a61ca1a14a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">there are mainly two types of guidance used in image generation and edition: intra-modal used visual clues like segmentation maps. sketch maps and so on, and inter-modal leverage texts, audios, scene graph</span></span></p></div><h2 id="https://www.notion.so/89f77ec8de1844ddb6ea8a5caeef91e7" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/89f77ec8de1844ddb6ea8a5caeef91e7"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3.1 different guiding modalities</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/ac5370258e93412ea62bc55ab80ece25" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">visual guidance</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/dda010c080164b2fa0c1d323ab661852" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">segmentation maps, keypoints, sketch&amp;edge&amp;scribe, scene layouts, depth map, normal map, trace map</span></span></li><li id="https://www.notion.so/9148c3bf8a5c413eb841d935c42a3e80" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">due to their inherent capacity to convey spatial and structural details, they can act as a pixel-level guidance so that can be easily integrated into image generating/editing process.</span></span></li><li id="https://www.notion.so/b0b2b9c78f7647cbb92ea96340fcdbed" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">visual guidance encoding: CNN, Transformers</span></span></li></ul></li><li id="https://www.notion.so/8bfc95b1e87d431bbb0d62ffc29d6a22" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">text guidance</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/57461555fede4cbfa4e0ff1816f429ec" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">text can only convey visual concepts, can be ambiguous</span></span></li><li id="https://www.notion.so/2361e1cf33f647fc94b6eba9139dc942" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">learn an accurate and reliable mapping is difficult because of modality gap.</span></span></li><li id="https://www.notion.so/3e1baf514ba64d0c91f9265a240b0bd3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">text guidance encoding: CLIP yields informative text embeddings</span></span></li></ul></li><li id="https://www.notion.so/0d129878f9354451b9088e7351c5e933" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Audio guidance</span></span></li><li id="https://www.notion.so/8cb1bf63fab34358b687dcf7898dc1a2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">other modality guidance</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/42193670aa2a483b99bb36a1d66ce4c8" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">scene graph</span></span></li><li id="https://www.notion.so/1316b2136ff04237accd60557d35eca5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">brain signal </span></span></li><li id="https://www.notion.so/239dc94069ec4169b370960db49e2b27" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">mouse track</span></span></li></ul></li></ul><h2 id="https://www.notion.so/d31104a7d98940f0b5af3d161566aaed" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/d31104a7d98940f0b5af3d161566aaed"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3.2 GAN-based approaches (some parts omitted)</span></span></h2><h3 id="https://www.notion.so/c7cc1d45c9594364be5117c5eb9e95f9" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/c7cc1d45c9594364be5117c5eb9e95f9"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">conditional GANs</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/78030b439b6c40b1abb282397493d383" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">condition the generation process on additional information, and this is achieved by feeding guidance into both generator and discriminator</span></span></li><li id="https://www.notion.so/360cd5f842fa4bce99665348dfe1008b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">guidance is encoded into 1d or 2d features. the drawback is they struggle to capture complex scene structural relationships between guidance and real images.</span></span></li><li id="https://www.notion.so/9c2e831c5bf4475b9f3e861a3ddac203" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">in order to tackle this circumstances, using an attention module to do the alignment. </span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/1383e3e269a84e1386e4516fcf2d0306" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">by applying region-wise condition incorporation, it can direct generator’s attention to particular image regions during generation.</span></span></li><li id="https://www.notion.so/6d97b82a9bda4404bec5f9c4903ebb8e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">complex conditions can be mapped to an intermediary representation.</span></span></li></ul></li><li id="https://www.notion.so/ce457fca3edf4f9fabc25a3fafe67462" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">model architecture</span></span></li><li id="https://www.notion.so/2aa91538554f48979aedeb4278d1b2cb" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Loss design</span></span></li></ul><h3 id="https://www.notion.so/e3708f0923694a22ae1628385324b6b0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/e3708f0923694a22ae1628385324b6b0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inversion of Unconditional GANs</span></span></h3><div id="https://www.notion.so/b69021e2810846ad847c0225e6fcd0f1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">inversion means to invert a given image back into the latent space of the GAN</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/4cae5aff54e044b7962972d84d7989ec" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">explicit cross-modal alignment</span></span></li><li id="https://www.notion.so/7c29f1cc3adc4b4bb0d679256e77151a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">implicit cross-modal supervision</span></span></li></ul><div id="https://www.notion.so/85f462d9d92f46efb67b50f5233ed45c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h2 id="https://www.notion.so/3a6d2805297b47d9ad8cea03563d5851" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/3a6d2805297b47d9ad8cea03563d5851"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgPink">3.3 Diffusion-based approaches(Highlighting)</mark></strong></span></span></h2><h3 id="https://www.notion.so/94d76c0fae684c519f589c69bfccc036" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/94d76c0fae684c519f589c69bfccc036"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">扩散模型简介</span></span></h3><div id="https://www.notion.so/bd743127246141bda62f30c6312c658a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">扩散模型来源于分子热动力学中的扩散过程，即对输入</span><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Math" data-latex="X_{0}"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">X_{0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="SemanticString">构建一个离散步骤的马尔科夫链，向其不断加入噪声，直至成为无法辨识的纯噪声 </span><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Math" data-latex="X_{T}"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">X_{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="SemanticString"> 。</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgPink">模型的学习目标是 从噪声分布出发，逐渐去除噪声  将图片还原至原始的数据分布。</mark></em></span></span></p></div><h3 id="https://www.notion.so/8695581f63e04b198f1f77df193d9df6" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/8695581f63e04b198f1f77df193d9df6"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">DDPM时代的image editing，利用输入图像引导生成，无引导生成技术</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/31b9b7df57d144fe9a3eccbaa22655ec" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">前向过程的离散加噪过程 被证明为 连续时间里的随机过程的离散化形式。</span></span></li><li id="https://www.notion.so/5819156f7a474057b7003bb3a6ee005d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">DDPM的优化目标—预测每一步所添加的噪声，可理解为 学习一个当前输入对目标数据分布的最优梯度方向，即学习一个数据空间上最优的梯度方向。</span></span></li><li id="https://www.notion.so/077fc986086f4f6da687c9929158384a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">DDPM对图像加噪后再去噪，无法得到同一张图像，除非固定种子数。但是，通过在后向去噪过程中使用确定的常微分方程，可以得到确定性的采样结果</span></span></li><li id="https://www.notion.so/0c4a93288a92444fbe0196794c5744b0" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">DDIM证明了 在前向扩散时，通过构造后向常微分方程的逆过程，可以得到前向过程的最终加噪结果。这个结论是的扩散生成变得高度可控，也催生了一系列可控图片生成工作。</span></span></li></ul><h3 id="https://www.notion.so/faa0f05e188f4a91be2c8c22217c657c" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/faa0f05e188f4a91be2c8c22217c657c"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">基于迭代去噪过程的图像编辑</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/0c3fe09deb1c4bddb8b9c13163bfa6e9" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">Conditioning Method for DDPMs</mark></span></span></li></ul><div id="https://www.notion.so/28fce2f6deac476f8f70dc7898b8e429" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">前向时信息逐渐丢失，后向时逐渐从噪声中补全。一种直觉的想法是 保存前向过程中每一步的噪声图像，然后与后向过程的噪声图像混合，这样来影响后向过程的生成结果。并且通过影响混合时注入的前向信息的多少，或者后向过程注入信息的时间步的多少，来控制生成图像与原始图像的相似程度。</span></span></p></div><div id="https://www.notion.so/fcbf1e625c2046b0b46ad5f89ef5f1ef" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">通过控制降维再升维的倍数来控制信息的留存比例，或者通过噪声在后向过程里添加的时间步数的多少来调整控制的强弱。</span></span></p></div><div id="https://www.notion.so/49cbcc94c4344debad3ff54e847a9ca4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">本篇文章的缺点是 只能全局修改，会保留原有图像的空间布局，无法局部调整，且无法做姿势和角度的变化</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/c7cc42c726674d809a323ca0e824afdb" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">SDEdit: guided image synthesis and editing with stochastic differential equations</mark></span></span></li></ul><div id="https://www.notion.so/94708dfca1de4cd5b820622150d4bb74" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">与上一篇文章的思想一脉相承，不同点在于本文中提出 在前向加噪过程中控制不加噪至纯噪声，而是加噪到中间过程使其保留一些低频信息。调控了信息保留的多少，实际上等价于 调控生成与原图的i相似程度。</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/fe17b6994f8147bcb7d5f51cd8042e68" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">RePaint: Inpainting using denoising diffusion probabilistic models</mark></span></span></li></ul><div id="https://www.notion.so/d73d43fcc0684a65a26ed4ed7305763e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">通过对图像进行mask操作，将局部控制变为image inpainting（图像补全/修复）任务。想法是记录前向过程中每一步的噪声图像，在后向过程中，将unmasked区域从前向过程的记录中抽取出来，而已masked的区域则由噪声填充，这样拼合成一张完整的图像后，再开始迭代去噪。之后的每一步去噪操作都更新unmasked区域为 前向过程的记录，同时masked区域更新为后向去噪的结果。</span></span></p></div><div id="https://www.notion.so/ac628c3921fc438eb46d9849e84c110e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">此处我们可以看到一个很大的弊端：掩码区域中所有信息实质上被全部丢弃了，重新生成的结果往往只在局部语义上自洽的，失去了全局语义的一致性。</span></span></p></div><div id="https://www.notion.so/2a2919eb1fb842ad8f250f403e53000f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgBlue">在论文中，作者给出了一个十分有启发性的洞见：在后向去噪时，拼合图像中包含了前向扩散过程中保存的 来自原图的静态输出，即使我们在后向去噪时不断地尝试生成 语义一致性地输出，但在下一步拼合图像时的使用的 仍旧来自原图的静态输出，导致全局语义不一致。</mark></span><span class="SemanticString">同时随着去噪过程的逐渐深入，方差逐渐减小，使得更正语义变得更为困难。</span></span></p></div><div id="https://www.notion.so/2eaa6ef23f384e439a07be8a4920e10a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">作者们提出的解决方案是在每一次去噪时，都重新将去噪后的拼合结果</span><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Math" data-latex="x_{t-1}"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="SemanticString"> 加一次噪声至</span><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Math" data-latex="x_{t}"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="SemanticString">,  每次迭代都重复同样的后向的去噪步骤。如此便可以得到语义一致性的输出。</span></span></p></div><div id="https://www.notion.so/c8cfd25916c84498876dc41d7e43f546" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">但是，由于其框架仍然是基于迭代去噪过程的unconditional DDPM，对掩码区域所做的调控仍旧十分有限，只能借助于随机性重新生成。</span></span></p></div><h3 id="https://www.notion.so/8a66fe6531bc4efbbcee185e5b0dc09a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/8a66fe6531bc4efbbcee185e5b0dc09a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">基于显示分类器的guided image synthesis</span></span></h3><div id="https://www.notion.so/84454f9a64464b0bbba45f252b1a1276" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">利用贝叶斯定理的思想，有条件生成的梯度 可以拆解为 一个基于显示分类器的梯度加一个常规的无条件生成的梯度， 即在训练无条件生成模型的同时，额外训练一个新的基于噪声输入的分类器。</span></span></p></div><div id="https://www.notion.so/7e7405654dad49528f3b3ade4e81307c" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2f766b29-2ea4-4bd3-b5a4-e00aa9e137a5%2F02349226-9593-44a7-b6e2-9f6c55600c5b%2FUntitled.png?width=612&amp;table=block&amp;id=7e740565-4dad-4952-8f3b-3ade4e81307c"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F2f766b29-2ea4-4bd3-b5a4-e00aa9e137a5%2F02349226-9593-44a7-b6e2-9f6c55600c5b%2FUntitled.png?width=612&amp;table=block&amp;id=7e740565-4dad-4952-8f3b-3ade4e81307c" style="width:612px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/553f99137a474a90a92397076aac0556" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">Diffusion Models Beat GANs on Image Synthesis</mark></span></span></li></ul><div id="https://www.notion.so/454c297ee9764dea9bb4302777fc82fb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这篇论文有极大方面的贡献：</span></span></p><div class="Text__Children"><ol class="NumberedListWrapper"><li id="https://www.notion.so/5e149efa2c2148fd96021e030d789127" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">对UNet构架的探索：在UNet中前半段下采样的部分 添加了Att Pooling作为分类器。</span></span></li><li id="https://www.notion.so/6ae55d20a0fc48abb296a868b10e6e7f" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">显示分类器在DDPM, DDIM 的具体算法及其推导</span></span></li><li id="https://www.notion.so/8c8a53ac442f4d628be9bd272297f7d8" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">condition-guided generation的质量和多样性的权衡</span></span></li></ol></div></div><div id="https://www.notion.so/78d91a57738045f1a14d6ce8b9f47255" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这篇论文的缺点是 由于训练数据来自 DDPM前向加噪结果的增广后的数据，导致在这些噪声图像上训练后的分类判断无法复用常见的分类模型，所以需要自己训练一个新的模型，且只能按照类别生成，限制了使用场景。</span></span></p></div><h3 id="https://www.notion.so/a1fcd2e8480a45689da524a97b442a67" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/a1fcd2e8480a45689da524a97b442a67"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">基于CLIP的多模态guided  image generation</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/ea8121caedb841f19937a6310652e828" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedBg SemanticString__Fragment--BgYellow">More control for free! image synthesis with semantic diffusion guidance(SDG)</mark></span></span></li></ul><div id="https://www.notion.so/c2a4b07b63ea4f32ab7016fee12d2ab2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/8becf3adfd654eb499e3cbbb6e0dfb6b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/b4d647e3ad02445f8c99625eda0c41e5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Blended Diffusion for Text-driven editing of natural language</span></span></li><li id="https://www.notion.so/b9decf01310f4c0384c8b1285e5dbcae" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">DiffCLIP: text-guided diffusion models for robust image manipulation</span></span></li><li id="https://www.notion.so/45b9a04a259049829a0408f6492b194e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">diffusion models already have a semantic latent space</span></span></li></ul><div id="https://www.notion.so/4769948d45a0456aaf9a5153bf80384e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/529bc23294ed458e9784fad135705abd" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/529bc23294ed458e9784fad135705abd"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">基于隐式分类器的文生图大模型</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/69755272f45545a196c30ae205cffb8e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">classifier-free diffusion models</span></span></li></ul><div id="https://www.notion.so/bdd4165b2a6d4018985d81d88f07432f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/6845a8da86c14750af97dee8d9e6a9b8" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/6845a8da86c14750af97dee8d9e6a9b8"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">在隐式分类器上引导生成过程的 conditional generation</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/70201924358a40e2ad9b3fd080077c5a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Imagic: text-based real image editing with diffusion models</span></span></li><li id="https://www.notion.so/0dc03eadb2054cbf998811d641802314" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">UniTune: text-driven image editing by fine tuning an image generation model on a single image</span></span></li><li id="https://www.notion.so/7a0801c005d540e1a8d8158966174717" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">DreamBooth: fine tuning text-to-image diffusion models for subject-driven generation</span></span></li><li id="https://www.notion.so/9796d8b78b63416fba84767e20eb1447" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">DiffEdit: diffusion-based semantic image editing with mask guidance</span></span></li><li id="https://www.notion.so/951f8ca12cd84bd38962c90cb93843e5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">prompt-to-prompt image editing with cross-attention control</span></span></li></ul><div id="https://www.notion.so/316916139f4140698dffe123b1d15285" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h2 id="https://www.notion.so/182a6dc33793471ca3b7e1969146a4d9" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/182a6dc33793471ca3b7e1969146a4d9"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3.4 Autoregressive approaches</span></span></h2><div id="https://www.notion.so/adb7c91e5b074c66a02478497dbeb803" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/6e2dec846749452ebbc1cae6db463604" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h2 id="https://www.notion.so/54297840b9bd4007a8cf0334307f5776" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/54297840b9bd4007a8cf0334307f5776"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3.5 NeRF-based approaches</span></span></h2><div id="https://www.notion.so/241eb18c687a43368063f09405da053e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/360073881d3640699d5580b677931d9d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/6d89a972c8cd4b23b3c3f99651387ff3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/af5672a98905416baeac1efe47829fbd" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/af5672a98905416baeac1efe47829fbd"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">4 Datasets &amp; Evaluation Metrics</span></span></h1><div id="https://www.notion.so/bc3a1befc9d14503a6e46413045882bb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/b928d81ba0b44f218219eefb47b433c5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/0538300dd40a424cb7121b227c9c90c6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/63e889380ccf4f699062665ba220d0dc" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/1529791f458348959b259e5902575d38" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/9f7850a73e5143e48cc65c0b286a24c6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/c2092cb44eea4120bca1a93202d08d1a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/c2092cb44eea4120bca1a93202d08d1a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">5. open challenges and discussion</span></span></h1><div id="https://www.notion.so/982759fa545d449d9a203e8996bc6ccf" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/1931038162e24e318ed38e2d3028b499" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/96903e9894ff4d58a4109ab1d64c3e4a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/7e2f2b07090b46b7877bde689f7117aa" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/7e2f2b07090b46b7877bde689f7117aa"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">4. Discussion &amp;&amp; Limitation</span></span></h1></article>
  <footer class="Footer">
  <div>&copy; Paper Reading 2023</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>
</body>

</html>